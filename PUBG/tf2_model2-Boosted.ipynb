{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tf2_model2-Boosted.ipynb', '.ipynb_checkpoints', 'test.csv', 'train.csv', 'submission3.csv', 'Keras_-_PUBG.ipynb', 'sample_submission.csv', 'tf2_model1.ipynb', 'estimator_submission.csv', 'submission1.csv', 'estimator_api.ipynb', 'PUBG_submit.ipynb', 'Esti_works.ipynb', 'tf2_model3-Keras.ipynb', 'EDA.ipynb', 'Untitled.ipynb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import keras\n",
    "import glob\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def load_data(train_path='train.csv', test_path='test.csv'):\n",
    "    train = pd.DataFrame.from_csv(train_path, index_col=\"Id\")\n",
    "    test = pd.DataFrame.from_csv(test_path, index_col=\"Id\")\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ff8ff18bf730f63f59bac68283bfcd861384e7e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazukav/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n",
      "/home/lazukav/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    if 'winPlacePerc' in data:\n",
    "        data.winPlacePerc = np.where(data.winPlacePerc >= 0.5 , 1, 0)    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess(train)\n",
    "test = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "f45d65f4d93099f8f5cb8734dc9252d431b24c2e"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train.drop('winPlacePerc', axis=1), train.winPlacePerc, test_size=0.2, shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c178b258d912a35eaeb6732308317dfc6b714e0f"
   },
   "outputs": [],
   "source": [
    "# cols = [tf.feature_column.numeric_column(i) for i in X_train.select_dtypes(exclude=['object'])]\n",
    "# for i in train.select_dtypes(include=['object']).columns.values:\n",
    "#     cols.append(tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(key=i, vocabulary_list=train[i].unique())))\n",
    "# cols.append(matchType)\n",
    "cols = [tf.feature_column.numeric_column(i) for i in ['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "f31aa48af2d17858430c624cf97415d8349227dc"
   },
   "outputs": [],
   "source": [
    "def train_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cols,\n",
    "    m_dir,\n",
    "    periods):\n",
    "\n",
    "    steps_per_period = steps / periods  \n",
    "\n",
    "    training_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        shuffle = True,\n",
    "    )\n",
    "\n",
    "    ptraining_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "    )\n",
    "    \n",
    "    validation_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = X_test,\n",
    "        y = y_test,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "    )\n",
    "\n",
    "    classifier = tf.estimator.BoostedTreesClassifier(\n",
    "        feature_columns=cols,\n",
    "        n_batches_per_layer=batch_size,\n",
    "        n_classes=2,\n",
    "        n_trees=20,\n",
    "        model_dir=m_dir\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "#     print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    for period in range (0, periods):\n",
    "\n",
    "        classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        classifier.evaluate(input_fn=validation_input_fn)\n",
    "        print(\"period:\", period + 1)\n",
    "    print(\"Done\")\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "de84a50369adbc68661bdb9b9ffdbc74f3ee49bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0329 07:35:38.471166 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0329 07:35:38.503226 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0329 07:35:38.505985 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0329 07:35:38.529292 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0329 07:35:38.532249 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2758: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0329 07:35:38.569791 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/data_flow_ops.py:1236: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss error (on validation data):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 07:35:38.804695 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:35:39.066659 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:877: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0329 07:35:39.250919 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:35:39.349242 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:35:40.485117 139674315347712 basic_session_run_hooks.py:713] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0329 07:35:40.648555 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:35:41.195840 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0329 07:35:41.631695 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0329 07:35:41.660523 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0329 07:35:41.834741 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0329 07:36:26.269905 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 07:36:26.979589 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W0329 07:36:27.264679 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:36:27.366013 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:36:27.806025 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:36:28.818827 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0329 07:36:28.849453 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 07:37:17.072968 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:37:17.164597 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:37:17.564918 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:37:18.514564 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0329 07:37:18.543786 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 07:38:04.160445 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:38:04.252361 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:38:04.636664 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:38:05.683497 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0329 07:38:05.711314 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 07:38:50.427281 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:38:50.509525 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:38:50.854546 139674315347712 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:965: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "W0329 07:38:50.884431 139674315347712 meta_graph.py:447] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0329 07:38:51.933487 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0329 07:38:51.962160 139674315347712 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period: 5\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model = train_classification_model(\n",
    "    learning_rate=0.01,\n",
    "    steps=100,\n",
    "    batch_size=20,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    cols=cols,\n",
    "    m_dir='/tmp/model2',\n",
    "    periods=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "c13a2e2cf497db28e365cec61e91bc8842cedcf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "scores3 = model.predict(input_fn=tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    x = test,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False,\n",
    "))\n",
    "print(\"done!\")\n",
    "\n",
    "res = []\n",
    "for i, p in enumerate(scores3):\n",
    "#     print(i, '/', len(test))\n",
    "    res.append(p['class_ids'][0])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "310e6a03d31de3136ab1c78fd4437a4d737b11ec"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\"Id\": test.index, \"winPlacePerc\": res},\n",
    "    columns=[\"Id\", \"winPlacePerc\"]\n",
    ")\n",
    "submission.to_csv(\"submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28263322f095c8017fce099b4019d6d0d4d5b386"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cf760ae784e6aa0597d794cc2ad9aa4bb6888e2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
