{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "cd67d0e81fc0471d6de77d43f980779c2aa7efce",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !sudo python3 -m pip install tensorflow==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tf2_model2-Boosted.ipynb', '.ipynb_checkpoints', 'test.csv', 'train.csv', 'submission3.csv', 'Keras_-_PUBG.ipynb', 'sample_submission.csv', 'tf2_model1.ipynb', 'estimator_submission.csv', 'estimator_api.ipynb', 'PUBG_submit.ipynb', 'Esti_works.ipynb', 'tf2_model3-Keras.ipynb', 'EDA.ipynb', 'Untitled.ipynb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import keras\n",
    "import glob\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\".\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "4aa3fe5bc24ae9ca0071d35f8dab37a76908a5df"
   },
   "outputs": [],
   "source": [
    "def load_data(train_path='train.csv', test_path='test.csv'):\n",
    "    train = pd.DataFrame.from_csv(train_path, index_col=\"Id\")\n",
    "    test = pd.DataFrame.from_csv(test_path, index_col=\"Id\")\n",
    "#     train = train.reindex(np.random.permutation(train.index))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "aa1308c1991834c23c6656ca885d06a29e24a05f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazukav/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n",
      "/home/lazukav/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e0d4f602572d18605a7fd815aa52b7338be3a858"
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    if 'winPlacePerc' in data:\n",
    "        data.winPlacePerc = np.where(data.winPlacePerc >= 0.5 , 1, 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess(train)\n",
    "test = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7446c0cedf0abccd1541226d50bd0cf93682cf46"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train.drop('winPlacePerc', axis=1), train.winPlacePerc, test_size=0.2, shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4bafcc3d8c4048cebfe0f38cf8a5bf2c8f79e5ee"
   },
   "outputs": [],
   "source": [
    "# X_train.select_dtypes(exclude=['object']).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d052737cdec09fcf0b1359757251ac0545781de9"
   },
   "outputs": [],
   "source": [
    "# cols = [tf.feature_column.numeric_column(i) for i in X_train.select_dtypes(exclude=['object']).columns.values]\n",
    "# for i in train.select_dtypes(include=['object']).columns.values:\n",
    "#     cols.append(tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(key=i, vocabulary_list=train[i].unique())))\n",
    "# cols.append(matchType)\n",
    "cols = [tf.feature_column.numeric_column(i) for i in ['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "68135c2b59c8c061ae62e988b80f63d86d146bf5"
   },
   "outputs": [],
   "source": [
    "# def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "#     def input_function():\n",
    "#         ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "#         if shuffle:\n",
    "#             ds = ds.shuffle(1000)\n",
    "#         ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "#         return ds\n",
    "#     return input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "fe1ef139441223dfc12405c1f6f08ef9b94d1597"
   },
   "outputs": [],
   "source": [
    "def train_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cols,\n",
    "    m_dir,\n",
    "    periods):\n",
    "\n",
    "    steps_per_period = steps / periods  \n",
    "\n",
    "#     training_input_fn = make_input_fn(X_train, y_train, shuffle=True)\n",
    "\n",
    "#     ptraining_input_fn = make_input_fn(X_train, y_train, num_epochs=1, shuffle=False)\n",
    "\n",
    "#     validation_input_fn = make_input_fn(X_test, y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "    training_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        shuffle = True,\n",
    "    )\n",
    "    \n",
    "    ptraining_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "    )\n",
    "    \n",
    "    validation_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = X_test,\n",
    "        y = y_test,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "    )\n",
    "\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=cols,\n",
    "        n_classes=2,\n",
    "        hidden_units=[64, 128, 64],\n",
    "        model_dir=m_dir\n",
    "    )\n",
    "\n",
    "    # Train the model, but do so inside a loop so that we can periodically assess\n",
    "    # loss metrics.\n",
    "    print(\"Training model...\")\n",
    "#     print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    for period in range (0, periods):\n",
    "        # Train the model, starting from the prior state.\n",
    "        classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        classifier.evaluate(input_fn=validation_input_fn)\n",
    "        print(\"period:\", period + 1)\n",
    "    print(\"Done\")\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "5e8bd8a4f730aa22e1854f72e4e4bb2dfaab4ca2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "period: 1\n",
      "period: 2\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "model = train_classification_model(\n",
    "    learning_rate=0.005,\n",
    "    steps=100,\n",
    "    batch_size=10,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    cols=cols,\n",
    "    periods=5,\n",
    "    m_dir='/tmp/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "bd3bee6cd2e3655a10a18ee39eba93eaed777894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "scores1 = model.predict(input_fn=tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "    x = test,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False,\n",
    "))\n",
    "print(\"done!\")\n",
    "res = []\n",
    "for i, p in enumerate(scores1):\n",
    "#     print(i)\n",
    "    res.append(p['class_ids'][0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "707b76b4c661a0fe43ca84dffe6f382582816f90"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\"Id\": test.index, \"winPlacePerc\": res},\n",
    "    columns=[\"Id\", \"winPlacePerc\"]\n",
    ")\n",
    "submission.to_csv(\"submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
