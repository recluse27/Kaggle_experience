{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics, model_selection\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    Y = data['Survived']\n",
    "    X = data.drop(['Survived'], axis=1)\n",
    "    return X, Y\n",
    "\n",
    "def load_data(train_path='train.csv', test_path='test.csv'):\n",
    "    train = pd.DataFrame.from_csv(train_path, index_col=0)\n",
    "    test_X = pd.DataFrame.from_csv(test_path, index_col=0)\n",
    "    train_X, train_Y = data_split(train)\n",
    "              \n",
    "    return train_X, train_Y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_data(data):\n",
    "    sex_mapping = {\n",
    "        'male': 1,\n",
    "        'female': 0\n",
    "    }\n",
    "    data['Sex'] = data['Sex'].map(sex_mapping)\n",
    "    male_mean_age = data[data[\"Sex\"]==1][\"Age\"].mean()\n",
    "    female_mean_age = data[data[\"Sex\"]==0][\"Age\"].mean()\n",
    "    \n",
    "    data.loc[ (data[\"Sex\"]==1) & (data[\"Age\"].isnull()), \"Age\"] = male_mean_age\n",
    "    data.loc[ (data[\"Sex\"]==0) & (data[\"Age\"].isnull()), \"Age\"] = female_mean_age\n",
    "    data.drop(['Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "    data = pd.get_dummies(data, columns=['Pclass'])\n",
    "    data['Relatives'] = data['SibSp'] + data['Parch']\n",
    "\n",
    "    return data\n",
    "\n",
    "train_X = proc_data(train_X)\n",
    "test_X = proc_data(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = tf.feature_column.numeric_column('Sex')\n",
    "age = tf.feature_column.numeric_column('Age')\n",
    "age_bucket = tf.feature_column.bucketized_column(age, [8, 16, 21, 32, 40, 55])\n",
    "sibsp = tf.feature_column.numeric_column('SibSp')\n",
    "parch = tf.feature_column.numeric_column('Parch')\n",
    "pclass1 = tf.feature_column.numeric_column('Pclass_1')\n",
    "pclass2 = tf.feature_column.numeric_column('Pclass_2')\n",
    "pclass3 = tf.feature_column.numeric_column('Pclass_3')\n",
    "relatives = tf.feature_column.numeric_column('Relatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train_X, train_Y, test_size=0.2, shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cols,\n",
    "    m_dir,\n",
    "    periods):\n",
    "\n",
    "    steps_per_period = steps / periods  \n",
    "\n",
    "    training_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    ptraining_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    validation_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        x=X_test,\n",
    "        y=y_test,\n",
    "        num_epochs=1,\n",
    "        shuffle=False \n",
    "    )\n",
    "\n",
    "    my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=cols,\n",
    "        n_classes=2,\n",
    "        optimizer=my_optimizer,\n",
    "        hidden_units=[64, 128, 64],\n",
    "        model_dir=m_dir\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    for period in range (0, periods):\n",
    "        classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        classifier.evaluate(input_fn=validation_input_fn)\n",
    "\n",
    "        training_predictions = list(classifier.predict(input_fn=ptraining_input_fn))\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
    "        training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
    "        training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id, 2)\n",
    "\n",
    "        validation_predictions = list(classifier.predict(input_fn=validation_input_fn))\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
    "        validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
    "        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id, 2)    \n",
    "        print(\"Hey\")\n",
    "\n",
    "        training_log_loss = metrics.log_loss(y_train, training_pred_one_hot)\n",
    "        validation_log_loss = metrics.log_loss(y_test, validation_pred_one_hot)\n",
    "\n",
    "        print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
    "\n",
    "        training_errors.append(training_log_loss)\n",
    "        validation_errors.append(validation_log_loss)\n",
    "    print(\"Model training finished.\")\n",
    "\n",
    "    _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "\n",
    "    final_predictions = classifier.predict(input_fn=validation_input_fn)\n",
    "    final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
    "\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, final_predictions)\n",
    "    print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
    "\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.plot(training_errors, label=\"training\")\n",
    "    plt.plot(validation_errors, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test, final_predictions)\n",
    "    \n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "    ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "    ax.set_aspect(1)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [sex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = train_classification_model(\n",
    "    learning_rate=0.01,\n",
    "    steps=100,\n",
    "    batch_size=20,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    cols=cols,\n",
    "    m_dir='/tmp/model1',\n",
    "    periods=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = model1.predict(input_fn=tf.estimator.inputs.pandas_input_fn(x=test_X,\n",
    "                                                                      num_epochs=1,\n",
    "                                                                      shuffle=False))\n",
    "\n",
    "res = []\n",
    "for i, p in enumerate(scores1):\n",
    "    res.append([i + 892, p['class_ids'][0]])   \n",
    "\n",
    "result = pd.DataFrame(res, columns=['PassengerId', 'Survived'])\n",
    "result.to_csv('model1.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
